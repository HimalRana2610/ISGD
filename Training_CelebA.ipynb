{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a341f3e",
   "metadata": {},
   "source": [
    "# CelebA Multi-Attribute Training with ConvNeXt Tiny\n",
    "\n",
    "This notebook trains a ConvNeXt Tiny model on 40,000 random images from the CelebA dataset for facial attribute prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30efbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5050 Laptop GPU\n",
      "Memory: 7.96 GB\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score, \n",
    "    precision_score, recall_score, confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d1d56",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8a6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Backbone: focalnet_tiny_srf\n",
      "Sample Size: 40000 images\n",
      "Training Configuration:\n",
      "  - Batch Size: 16\n",
      "  - Epochs: 3\n",
      "  - Learning Rate: 0.0001\n",
      "  - Image Size: 224x224\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BACKBONE = 'focalnet_tiny_srf'\n",
    "SAMPLE_SIZE = 40000  # Number of images to sample from CelebA\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_WORKERS = 0\n",
    "IMAGE_SIZE = 224\n",
    "VAL_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = './Data/CelebA'\n",
    "CSV_PATH = os.path.join(DATA_DIR, 'list_attr_celeba.csv')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'img_align_celeba')\n",
    "MODEL_SAVE_DIR = './Models'\n",
    "RESULTS_DIR = './Results'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Selected Backbone: {BACKBONE}\")\n",
    "print(f\"Sample Size: {SAMPLE_SIZE} images\")\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176edf9f",
   "metadata": {},
   "source": [
    "## Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18fbda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CelebA dataset...\n",
      "Original dataset shape: (202599, 41)\n",
      "Number of attributes: 40\n",
      "\n",
      "Sampled 40000 images from the dataset\n",
      "Final dataset shape: (40000, 41)\n",
      "\n",
      "Attributes (40):\n",
      "5_o_Clock_Shadow, Arched_Eyebrows, Attractive, Bags_Under_Eyes, Bald, Bangs, Big_Lips, Big_Nose, Black_Hair, Blond_Hair, Blurry, Brown_Hair, Bushy_Eyebrows, Chubby, Double_Chin, Eyeglasses, Goatee, Gray_Hair, Heavy_Makeup, High_Cheekbones, Male, Mouth_Slightly_Open, Mustache, Narrow_Eyes, No_Beard, Oval_Face, Pale_Skin, Pointy_Nose, Receding_Hairline, Rosy_Cheeks, Sideburns, Smiling, Straight_Hair, Wavy_Hair, Wearing_Earrings, Wearing_Hat, Wearing_Lipstick, Wearing_Necklace, Wearing_Necktie, Young\n",
      "\n",
      "Train set: 32000 samples\n",
      "Validation set: 8000 samples\n",
      "Original dataset shape: (202599, 41)\n",
      "Number of attributes: 40\n",
      "\n",
      "Sampled 40000 images from the dataset\n",
      "Final dataset shape: (40000, 41)\n",
      "\n",
      "Attributes (40):\n",
      "5_o_Clock_Shadow, Arched_Eyebrows, Attractive, Bags_Under_Eyes, Bald, Bangs, Big_Lips, Big_Nose, Black_Hair, Blond_Hair, Blurry, Brown_Hair, Bushy_Eyebrows, Chubby, Double_Chin, Eyeglasses, Goatee, Gray_Hair, Heavy_Makeup, High_Cheekbones, Male, Mouth_Slightly_Open, Mustache, Narrow_Eyes, No_Beard, Oval_Face, Pale_Skin, Pointy_Nose, Receding_Hairline, Rosy_Cheeks, Sideburns, Smiling, Straight_Hair, Wavy_Hair, Wearing_Earrings, Wearing_Hat, Wearing_Lipstick, Wearing_Necklace, Wearing_Necktie, Young\n",
      "\n",
      "Train set: 32000 samples\n",
      "Validation set: 8000 samples\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset Class\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, df, images_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get attribute columns (all except image_id)\n",
    "        self.attributes = [col for col in df.columns if col != 'image_id']\n",
    "        self.num_attributes = len(self.attributes)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['image_id']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_name}: {e}\")\n",
    "            # Return a black image as fallback\n",
    "            image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get labels for all attributes\n",
    "        # Convert -1 to 0 for binary classification (CelebA uses -1 for negative)\n",
    "        label_values = row[self.attributes].values.astype(np.float32)\n",
    "        label_values = np.where(label_values == -1, 0, label_values)\n",
    "        labels = torch.from_numpy(label_values)\n",
    "        \n",
    "        return image, labels\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading CelebA dataset...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Number of attributes: {len(df.columns) - 1}\")\n",
    "\n",
    "# Get attribute columns (all except image_id)\n",
    "attribute_cols = [col for col in df.columns if col != 'image_id']\n",
    "\n",
    "# Sample 40,000 images randomly\n",
    "if len(df) > SAMPLE_SIZE:\n",
    "    df = df.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    print(f\"\\nSampled {SAMPLE_SIZE} images from the dataset\")\n",
    "else:\n",
    "    print(f\"\\nDataset has {len(df)} images (less than {SAMPLE_SIZE}), using entire dataset\")\n",
    "\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"\\nAttributes ({len(attribute_cols)}):\")\n",
    "print(', '.join(attribute_cols))\n",
    "\n",
    "# Split dataset\n",
    "train_df, val_df = train_test_split(df, test_size=VAL_SPLIT, random_state=RANDOM_SEED)\n",
    "print(f\"\\nTrain set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(val_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc8d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 2000\n",
      "Validation batches: 500\n",
      "\n",
      "Training for 40 attributes\n"
     ]
    }
   ],
   "source": [
    "# Data Transforms (No Augmentation - Simple Resize and Normalize)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CelebADataset(train_df, IMAGES_DIR, transform=train_transform)\n",
    "val_dataset = CelebADataset(val_df, IMAGES_DIR, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                          shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, \n",
    "                        shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Get number of attributes\n",
    "num_attributes = train_dataset.num_attributes\n",
    "print(f\"\\nTraining for {num_attributes} attributes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f13b2",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ce6b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating focalnet_tiny_srf model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f7f6759cf1484b818815799cd38d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 28,072,364\n",
      "Trainable parameters: 28,072,364\n"
     ]
    }
   ],
   "source": [
    "# Multi-Attribute Classification Model\n",
    "class MultiAttributeModel(nn.Module):\n",
    "    def __init__(self, backbone_name, num_attributes, pretrained=True):\n",
    "        super(MultiAttributeModel, self).__init__()\n",
    "        self.backbone_name = backbone_name\n",
    "        \n",
    "        # Load ConvNeXt Tiny backbone\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained)\n",
    "        in_features = self.backbone.head.fc.in_features\n",
    "        self.backbone.head.fc = nn.Identity()\n",
    "        \n",
    "        # Classification head for multi-attribute prediction\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_attributes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# Create model\n",
    "print(f\"\\nCreating {BACKBONE} model...\")\n",
    "model = MultiAttributeModel(BACKBONE, num_attributes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6170b",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ec6d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy for multi-label classification\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87c991",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf71d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    accuracy = (all_preds == all_labels).mean()\n",
    "    \n",
    "    return running_loss / len(dataloader), accuracy\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1732fd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Training: focalnet_tiny_srf on CelebA\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/3\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:51<00:00,  5.70it/s, loss=0.2089]\n",
      "Training: 100%|██████████| 2000/2000 [05:51<00:00,  5.70it/s, loss=0.2089]\n",
      "Validation: 100%|██████████| 500/500 [00:49<00:00, 10.19it/s, loss=0.2296]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "  Train Loss: 0.2562\n",
      "  Val Loss: 0.2151\n",
      "  Val Accuracy: 0.9055\n",
      "  Learning Rate: 0.000100\n",
      "  ✓ Best model saved! (Val Loss: 0.2151)\n",
      "\n",
      "Epoch 2/3\n",
      "------------------------------------------------------------\n",
      "  ✓ Best model saved! (Val Loss: 0.2151)\n",
      "\n",
      "Epoch 2/3\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:41<00:00,  5.86it/s, loss=0.2134]\n",
      "Training: 100%|██████████| 2000/2000 [05:41<00:00,  5.86it/s, loss=0.2134]\n",
      "Validation: 100%|██████████| 500/500 [00:47<00:00, 10.55it/s, loss=0.2221]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "  Train Loss: 0.2072\n",
      "  Val Loss: 0.2010\n",
      "  Val Accuracy: 0.9123\n",
      "  Learning Rate: 0.000100\n",
      "  ✓ Best model saved! (Val Loss: 0.2010)\n",
      "\n",
      "Epoch 3/3\n",
      "------------------------------------------------------------\n",
      "  ✓ Best model saved! (Val Loss: 0.2010)\n",
      "\n",
      "Epoch 3/3\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:35<00:00,  5.96it/s, loss=0.2019]\n",
      "Training: 100%|██████████| 2000/2000 [05:35<00:00,  5.96it/s, loss=0.2019]\n",
      "Validation: 100%|██████████| 500/500 [00:47<00:00, 10.51it/s, loss=0.2091]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "  Train Loss: 0.1895\n",
      "  Val Loss: 0.2000\n",
      "  Val Accuracy: 0.9126\n",
      "  Learning Rate: 0.000100\n",
      "  ✓ Best model saved! (Val Loss: 0.2000)\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best Epoch: 3\n",
      "Best Val Loss: 0.2000\n",
      "============================================================\n",
      "\n",
      "  ✓ Best model saved! (Val Loss: 0.2000)\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best Epoch: 3\n",
      "Best Val Loss: 0.2000\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting Training: {BACKBONE} on CelebA\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        model_path = os.path.join(MODEL_SAVE_DIR, f'celeba_{BACKBONE}_best.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        }, model_path)\n",
    "        print(f\"  ✓ Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Best Epoch: {best_epoch}\")\n",
    "print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a967ab",
   "metadata": {},
   "source": [
    "## Load Best Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b3c172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model for evaluation...\n",
      "Model ready for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Load best model for evaluation\n",
    "print(\"Loading best model for evaluation...\")\n",
    "model_path = os.path.join(MODEL_SAVE_DIR, f'celeba_{BACKBONE}_best.pth')\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "# Support both plain state_dict and wrapped dict formats\n",
    "state_dict = checkpoint\n",
    "if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "    state_dict = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(\"Model ready for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698c183",
   "metadata": {},
   "source": [
    "## Per-Attribute Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b5e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating per-attribute metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 500/500 [00:47<00:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (8000, 40)\n",
      "Labels shape: (8000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions on validation set\n",
    "print(\"\\nCalculating per-attribute metrics...\")\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc='Predicting'):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = probs > 0.5\n",
    "        \n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate all batches\n",
    "all_probs = np.vstack(all_probs)\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(f\"Predictions shape: {all_preds.shape}\")\n",
    "print(f\"Labels shape: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fdca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating metrics for each attribute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing attributes: 100%|██████████| 40/40 [00:00<00:00, 140.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OVERALL METRICS (Mean across all attributes)\n",
      "============================================================\n",
      "AUC                 : 0.9396\n",
      "ACCURACY            : 0.9126\n",
      "MACRO_F1            : 0.8156\n",
      "MICRO_F1            : 0.9126\n",
      "PRECISION           : 0.7743\n",
      "RECALL              : 0.6585\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for each attribute\n",
    "attribute_names = train_dataset.attributes\n",
    "results = []\n",
    "\n",
    "print(\"\\nCalculating metrics for each attribute...\")\n",
    "for i, attr_name in enumerate(tqdm(attribute_names, desc='Processing attributes')):\n",
    "    y_true = all_labels[:, i]\n",
    "    y_pred = all_preds[:, i]\n",
    "    y_prob = all_probs[:, i]\n",
    "    \n",
    "    # Skip if only one class present\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        print(f\"Warning: Attribute '{attr_name}' has only one class in validation set\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # F1 scores\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    \n",
    "    # Precision and Recall\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    \n",
    "    results.append({\n",
    "        'attribute': attr_name,\n",
    "        'auc': auc,\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate mean metrics\n",
    "mean_metrics = results_df[['auc', 'accuracy', 'macro_f1', 'micro_f1', 'precision', 'recall']].mean()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL METRICS (Mean across all attributes)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in mean_metrics.items():\n",
    "    print(f\"{metric.upper():20s}: {value:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68952af4",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df2b1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results saved to: ./Results\\celeba_focalnet_tiny_srf_metrics.csv\n",
      "\n",
      "Results preview:\n",
      "          attribute       auc  accuracy  macro_f1  micro_f1  precision  \\\n",
      "0  5_o_Clock_Shadow  0.959635  0.934000  0.821219  0.934000   0.703145   \n",
      "1   Arched_Eyebrows  0.910581  0.808375  0.783968  0.808375   0.596464   \n",
      "2        Attractive  0.910648  0.818750  0.818658  0.818750   0.817541   \n",
      "3   Bags_Under_Eyes  0.885462  0.842500  0.718132  0.842500   0.684261   \n",
      "4              Bald  0.995795  0.990250  0.887338  0.990250   0.715026   \n",
      "5             Bangs  0.986903  0.956250  0.911332  0.956250   0.889091   \n",
      "6          Big_Lips  0.753168  0.776250  0.626852  0.776250   0.556202   \n",
      "7          Big_Nose  0.883942  0.835625  0.750160  0.835625   0.724188   \n",
      "8        Black_Hair  0.956536  0.905375  0.862059  0.905375   0.805134   \n",
      "9        Blond_Hair  0.982927  0.956375  0.914956  0.956375   0.859518   \n",
      "\n",
      "     recall  \n",
      "0  0.656874  \n",
      "1  0.881063  \n",
      "2  0.828002  \n",
      "3  0.433698  \n",
      "4  0.857143  \n",
      "5  0.810945  \n",
      "6  0.301154  \n",
      "7  0.518079  \n",
      "8  0.765391  \n",
      "9  0.851730  \n",
      "\n",
      "============================================================\n",
      "TOP 10 ATTRIBUTES (by Macro F1)\n",
      "============================================================\n",
      "          attribute  macro_f1  accuracy      auc\n",
      "         Eyeglasses  0.981186  0.995500 0.998279\n",
      "               Male  0.970974  0.972000 0.997666\n",
      "        Wearing_Hat  0.951021  0.990375 0.996211\n",
      "   Wearing_Lipstick  0.931865  0.931875 0.985405\n",
      "Mouth_Slightly_Open  0.931060  0.931125 0.981622\n",
      "            Smiling  0.923999  0.924250 0.979481\n",
      "           No_Beard  0.921619  0.959875 0.986301\n",
      "         Blond_Hair  0.914956  0.956375 0.982927\n",
      "              Bangs  0.911332  0.956250 0.986903\n",
      "       Heavy_Makeup  0.906672  0.909625 0.977732\n",
      "\n",
      "============================================================\n",
      "BOTTOM 10 ATTRIBUTES (by Macro F1)\n",
      "============================================================\n",
      "       attribute  macro_f1  accuracy      auc\n",
      "        Big_Lips  0.626852  0.776250 0.753168\n",
      "     Pointy_Nose  0.629282  0.764750 0.796419\n",
      "     Narrow_Eyes  0.652661  0.904500 0.871084\n",
      "       Oval_Face  0.659181  0.757875 0.762287\n",
      "       Pale_Skin  0.690748  0.965750 0.963621\n",
      "Wearing_Necklace  0.698089  0.888125 0.866704\n",
      " Bags_Under_Eyes  0.718132  0.842500 0.885462\n",
      "   Straight_Hair  0.731645  0.849250 0.890118\n",
      "     Double_Chin  0.732294  0.959250 0.952587\n",
      "        Mustache  0.737750  0.964875 0.973406\n"
     ]
    }
   ],
   "source": [
    "# Save results CSV\n",
    "csv_filename = f'celeba_{BACKBONE}_metrics.csv'\n",
    "csv_path = os.path.join(RESULTS_DIR, csv_filename)\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n✓ Results saved to: {csv_path}\")\n",
    "print(f\"\\nResults preview:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "# Sort by F1 score and display top/bottom performing attributes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 ATTRIBUTES (by Macro F1)\")\n",
    "print(\"=\"*60)\n",
    "top_attrs = results_df.nlargest(10, 'macro_f1')[['attribute', 'macro_f1', 'accuracy', 'auc']]\n",
    "print(top_attrs.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BOTTOM 10 ATTRIBUTES (by Macro F1)\")\n",
    "print(\"=\"*60)\n",
    "bottom_attrs = results_df.nsmallest(10, 'macro_f1')[['attribute', 'macro_f1', 'accuracy', 'auc']]\n",
    "print(bottom_attrs.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274645d1",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b59bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE - SUMMARY\n",
      "============================================================\n",
      "Dataset: CelebA\n",
      "Backbone Model: focalnet_tiny_srf\n",
      "Total Parameters: 28,072,364\n",
      "Sample Size: 40000 images\n",
      "Training Samples: 32000\n",
      "Validation Samples: 8000\n",
      "Number of Attributes: 40\n",
      "Number of Epochs: 3\n",
      "Best Epoch: 3\n",
      "\n",
      "Model saved at: ./Models\\celeba_focalnet_tiny_srf_best.pth\n",
      "Results saved at: ./Results\\celeba_focalnet_tiny_srf_metrics.csv\n",
      "\n",
      "============================================================\n",
      "MEAN METRICS\n",
      "============================================================\n",
      "AUC                 : 0.9396\n",
      "ACCURACY            : 0.9126\n",
      "MACRO_F1            : 0.8156\n",
      "MICRO_F1            : 0.9126\n",
      "PRECISION           : 0.7743\n",
      "RECALL              : 0.6585\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ATTRIBUTE STATISTICS\n",
      "============================================================\n",
      "Total attributes evaluated: 40\n",
      "\n",
      "Metrics Range:\n",
      "  AUC: 0.7532 - 0.9983\n",
      "  Accuracy: 0.7579 - 0.9955\n",
      "  Macro F1: 0.6269 - 0.9812\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: CelebA\")\n",
    "print(f\"Backbone Model: {BACKBONE}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Sample Size: {SAMPLE_SIZE} images\")\n",
    "print(f\"Training Samples: {len(train_dataset)}\")\n",
    "print(f\"Validation Samples: {len(val_dataset)}\")\n",
    "print(f\"Number of Attributes: {num_attributes}\")\n",
    "print(f\"Number of Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Best Epoch: {best_epoch}\")\n",
    "print(f\"\\nModel saved at: {model_path}\")\n",
    "print(f\"Results saved at: {csv_path}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEAN METRICS\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in mean_metrics.items():\n",
    "    print(f\"{metric.upper():20s}: {value:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display attribute distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ATTRIBUTE STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total attributes evaluated: {len(results_df)}\")\n",
    "print(f\"\\nMetrics Range:\")\n",
    "print(f\"  AUC: {results_df['auc'].min():.4f} - {results_df['auc'].max():.4f}\")\n",
    "print(f\"  Accuracy: {results_df['accuracy'].min():.4f} - {results_df['accuracy'].max():.4f}\")\n",
    "print(f\"  Macro F1: {results_df['macro_f1'].min():.4f} - {results_df['macro_f1'].max():.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
